{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from collections import defaultdict\n",
    "from array import array\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "import math\n",
    "import numpy as np\n",
    "import collections\n",
    "from numpy import linalg as la\n",
    "import json\n",
    "import re\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'dataset_tweets_WHO.txt'\n",
    "\n",
    "#convert the text to json\n",
    "with open(path) as f:\n",
    "    tweets_json = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"contributors\": null,\n",
      "    \"coordinates\": null,\n",
      "    \"created_at\": \"Mon Oct 11 04:43:20 +0000 2021\",\n",
      "    \"display_text_range\": [\n",
      "        0,\n",
      "        140\n",
      "    ],\n",
      "    \"entities\": {\n",
      "        \"hashtags\": [],\n",
      "        \"symbols\": [],\n",
      "        \"urls\": [],\n",
      "        \"user_mentions\": [\n",
      "            {\n",
      "                \"id\": 3794682452,\n",
      "                \"id_str\": \"3794682452\",\n",
      "                \"indices\": [\n",
      "                    3,\n",
      "                    11\n",
      "                ],\n",
      "                \"name\": \"World Health Organization (WHO) Western Pacific\",\n",
      "                \"screen_name\": \"WHOWPRO\"\n",
      "            }\n",
      "        ]\n",
      "    },\n",
      "    \"favorite_count\": 0,\n",
      "    \"favorited\": false,\n",
      "    \"full_text\": \"RT @WHOWPRO: \\u201cMy patients are no different to my grandmother and grandfather.\\u201d \\n\\nLoyal to their oath, health workers like Dr Gantsengel Pur\\u2026\",\n",
      "    \"geo\": null,\n",
      "    \"id\": 1447422540335484932,\n",
      "    \"id_str\": \"1447422540335484932\",\n",
      "    \"in_reply_to_screen_name\": null,\n",
      "    \"in_reply_to_status_id\": null,\n",
      "    \"in_reply_to_status_id_str\": null,\n",
      "    \"in_reply_to_user_id\": null,\n",
      "    \"in_reply_to_user_id_str\": null,\n",
      "    \"is_quote_status\": false,\n",
      "    \"lang\": \"en\",\n",
      "    \"place\": null,\n",
      "    \"retweet_count\": 30,\n",
      "    \"retweeted\": false,\n",
      "    \"retweeted_status\": {\n",
      "        \"contributors\": null,\n",
      "        \"coordinates\": null,\n",
      "        \"created_at\": \"Sun Oct 10 14:00:00 +0000 2021\",\n",
      "        \"display_text_range\": [\n",
      "            0,\n",
      "            274\n",
      "        ],\n",
      "        \"entities\": {\n",
      "            \"hashtags\": [\n",
      "                {\n",
      "                    \"indices\": [\n",
      "                        195,\n",
      "                        203\n",
      "                    ],\n",
      "                    \"text\": \"COVID19\"\n",
      "                },\n",
      "                {\n",
      "                    \"indices\": [\n",
      "                        260,\n",
      "                        273\n",
      "                    ],\n",
      "                    \"text\": \"MentalHealth\"\n",
      "                }\n",
      "            ],\n",
      "            \"media\": [\n",
      "                {\n",
      "                    \"display_url\": \"pic.twitter.com/LCUgSGx0u8\",\n",
      "                    \"expanded_url\": \"https://twitter.com/WHOWPRO/status/1447200245549514758/video/1\",\n",
      "                    \"id\": 1396722733136846849,\n",
      "                    \"id_str\": \"1396722733136846849\",\n",
      "                    \"indices\": [\n",
      "                        275,\n",
      "                        298\n",
      "                    ],\n",
      "                    \"media_url\": \"http://pbs.twimg.com/media/E2IqcGcUcAQhwnN.jpg\",\n",
      "                    \"media_url_https\": \"https://pbs.twimg.com/media/E2IqcGcUcAQhwnN.jpg\",\n",
      "                    \"sizes\": {\n",
      "                        \"large\": {\n",
      "                            \"h\": 270,\n",
      "                            \"resize\": \"fit\",\n",
      "                            \"w\": 480\n",
      "                        },\n",
      "                        \"medium\": {\n",
      "                            \"h\": 270,\n",
      "                            \"resize\": \"fit\",\n",
      "                            \"w\": 480\n",
      "                        },\n",
      "                        \"small\": {\n",
      "                            \"h\": 270,\n",
      "                            \"resize\": \"fit\",\n",
      "                            \"w\": 480\n",
      "                        },\n",
      "                        \"thumb\": {\n",
      "                            \"h\": 150,\n",
      "                            \"resize\": \"crop\",\n",
      "                            \"w\": 150\n",
      "                        }\n",
      "                    },\n",
      "                    \"type\": \"photo\",\n",
      "                    \"url\": \"https://t.co/LCUgSGx0u8\"\n",
      "                }\n",
      "            ],\n",
      "            \"symbols\": [],\n",
      "            \"urls\": [],\n",
      "            \"user_mentions\": []\n",
      "        },\n",
      "        \"extended_entities\": {\n",
      "            \"media\": [\n",
      "                {\n",
      "                    \"additional_media_info\": {\n",
      "                        \"call_to_actions\": {\n",
      "                            \"visit_site\": {\n",
      "                                \"url\": \"https://www.who.int/mongolia\"\n",
      "                            }\n",
      "                        },\n",
      "                        \"description\": \"\",\n",
      "                        \"embeddable\": true,\n",
      "                        \"monetizable\": false,\n",
      "                        \"title\": \"Let us #SupportHealthCareWorkers on #WorldMentalHealthDay.\"\n",
      "                    },\n",
      "                    \"display_url\": \"pic.twitter.com/LCUgSGx0u8\",\n",
      "                    \"expanded_url\": \"https://twitter.com/WHOWPRO/status/1447200245549514758/video/1\",\n",
      "                    \"id\": 1396722733136846849,\n",
      "                    \"id_str\": \"1396722733136846849\",\n",
      "                    \"indices\": [\n",
      "                        275,\n",
      "                        298\n",
      "                    ],\n",
      "                    \"media_url\": \"http://pbs.twimg.com/media/E2IqcGcUcAQhwnN.jpg\",\n",
      "                    \"media_url_https\": \"https://pbs.twimg.com/media/E2IqcGcUcAQhwnN.jpg\",\n",
      "                    \"sizes\": {\n",
      "                        \"large\": {\n",
      "                            \"h\": 270,\n",
      "                            \"resize\": \"fit\",\n",
      "                            \"w\": 480\n",
      "                        },\n",
      "                        \"medium\": {\n",
      "                            \"h\": 270,\n",
      "                            \"resize\": \"fit\",\n",
      "                            \"w\": 480\n",
      "                        },\n",
      "                        \"small\": {\n",
      "                            \"h\": 270,\n",
      "                            \"resize\": \"fit\",\n",
      "                            \"w\": 480\n",
      "                        },\n",
      "                        \"thumb\": {\n",
      "                            \"h\": 150,\n",
      "                            \"resize\": \"crop\",\n",
      "                            \"w\": 150\n",
      "                        }\n",
      "                    },\n",
      "                    \"type\": \"video\",\n",
      "                    \"url\": \"https://t.co/LCUgSGx0u8\",\n",
      "                    \"video_info\": {\n",
      "                        \"aspect_ratio\": [\n",
      "                            16,\n",
      "                            9\n",
      "                        ],\n",
      "                        \"duration_millis\": 175000,\n",
      "                        \"variants\": [\n",
      "                            {\n",
      "                                \"bitrate\": 2176000,\n",
      "                                \"content_type\": \"video/mp4\",\n",
      "                                \"url\": \"https://video.twimg.com/amplify_video/1396722733136846849/vid/1280x720/RJvJVJZbErkaPtev.mp4?tag=14\"\n",
      "                            },\n",
      "                            {\n",
      "                                \"content_type\": \"application/x-mpegURL\",\n",
      "                                \"url\": \"https://video.twimg.com/amplify_video/1396722733136846849/pl/davAgaTXvo8mSYRa.m3u8?tag=14\"\n",
      "                            },\n",
      "                            {\n",
      "                                \"bitrate\": 832000,\n",
      "                                \"content_type\": \"video/mp4\",\n",
      "                                \"url\": \"https://video.twimg.com/amplify_video/1396722733136846849/vid/640x360/ABczbVfdO0SUm8At.mp4?tag=14\"\n",
      "                            },\n",
      "                            {\n",
      "                                \"bitrate\": 288000,\n",
      "                                \"content_type\": \"video/mp4\",\n",
      "                                \"url\": \"https://video.twimg.com/amplify_video/1396722733136846849/vid/480x270/CtFCaEeSa2TPEmH-.mp4?tag=14\"\n",
      "                            }\n",
      "                        ]\n",
      "                    }\n",
      "                }\n",
      "            ]\n",
      "        },\n",
      "        \"favorite_count\": 97,\n",
      "        \"favorited\": false,\n",
      "        \"full_text\": \"\\u201cMy patients are no different to my grandmother and grandfather.\\u201d \\n\\nLoyal to their oath, health workers like Dr Gantsengel Purev of \\ud83c\\uddf2\\ud83c\\uddf3 have worked day and night to protect and save patients from #COVID19 despite their own struggles and the impact on their own #MentalHealth. https://t.co/LCUgSGx0u8\",\n",
      "        \"geo\": null,\n",
      "        \"id\": 1447200245549514758,\n",
      "        \"id_str\": \"1447200245549514758\",\n",
      "        \"in_reply_to_screen_name\": null,\n",
      "        \"in_reply_to_status_id\": null,\n",
      "        \"in_reply_to_status_id_str\": null,\n",
      "        \"in_reply_to_user_id\": null,\n",
      "        \"in_reply_to_user_id_str\": null,\n",
      "        \"is_quote_status\": false,\n",
      "        \"lang\": \"en\",\n",
      "        \"place\": null,\n",
      "        \"possibly_sensitive\": false,\n",
      "        \"retweet_count\": 30,\n",
      "        \"retweeted\": false,\n",
      "        \"source\": \"<a href=\\\"https://studio.twitter.com\\\" rel=\\\"nofollow\\\">Twitter Media Studio</a>\",\n",
      "        \"truncated\": false,\n",
      "        \"user\": {\n",
      "            \"contributors_enabled\": false,\n",
      "            \"created_at\": \"Mon Oct 05 18:08:31 +0000 2015\",\n",
      "            \"default_profile\": false,\n",
      "            \"default_profile_image\": false,\n",
      "            \"description\": \"World Health Organization @WHO in the Western #Pacific Region, \\ud83c\\udfe0 to 1.9B in #Asia & #Oceania. See new tweets for updated #COVID19 advice. \\u27a1\\ufe0f RD @takeshi_kasai\",\n",
      "            \"entities\": {\n",
      "                \"description\": {\n",
      "                    \"urls\": []\n",
      "                },\n",
      "                \"url\": {\n",
      "                    \"urls\": [\n",
      "                        {\n",
      "                            \"display_url\": \"who.int/westernpacific\",\n",
      "                            \"expanded_url\": \"http://www.who.int/westernpacific\",\n",
      "                            \"indices\": [\n",
      "                                0,\n",
      "                                23\n",
      "                            ],\n",
      "                            \"url\": \"https://t.co/EblVamM8WW\"\n",
      "                        }\n",
      "                    ]\n",
      "                }\n",
      "            },\n",
      "            \"favourites_count\": 6152,\n",
      "            \"follow_request_sent\": false,\n",
      "            \"followers_count\": 219413,\n",
      "            \"following\": false,\n",
      "            \"friends_count\": 1229,\n",
      "            \"geo_enabled\": true,\n",
      "            \"has_extended_profile\": true,\n",
      "            \"id\": 3794682452,\n",
      "            \"id_str\": \"3794682452\",\n",
      "            \"is_translation_enabled\": false,\n",
      "            \"is_translator\": false,\n",
      "            \"lang\": null,\n",
      "            \"listed_count\": 668,\n",
      "            \"location\": \"Manila, Philippines\",\n",
      "            \"name\": \"World Health Organization (WHO) Western Pacific\",\n",
      "            \"notifications\": false,\n",
      "            \"profile_background_color\": \"000000\",\n",
      "            \"profile_background_image_url\": \"http://abs.twimg.com/images/themes/theme1/bg.png\",\n",
      "            \"profile_background_image_url_https\": \"https://abs.twimg.com/images/themes/theme1/bg.png\",\n",
      "            \"profile_background_tile\": false,\n",
      "            \"profile_banner_url\": \"https://pbs.twimg.com/profile_banners/3794682452/1616740141\",\n",
      "            \"profile_image_url\": \"http://pbs.twimg.com/profile_images/899826905532125184/yPM5mxkX_normal.jpg\",\n",
      "            \"profile_image_url_https\": \"https://pbs.twimg.com/profile_images/899826905532125184/yPM5mxkX_normal.jpg\",\n",
      "            \"profile_link_color\": \"3B94D9\",\n",
      "            \"profile_sidebar_border_color\": \"000000\",\n",
      "            \"profile_sidebar_fill_color\": \"000000\",\n",
      "            \"profile_text_color\": \"000000\",\n",
      "            \"profile_use_background_image\": false,\n",
      "            \"protected\": false,\n",
      "            \"screen_name\": \"WHOWPRO\",\n",
      "            \"statuses_count\": 10596,\n",
      "            \"time_zone\": null,\n",
      "            \"translator_type\": \"none\",\n",
      "            \"url\": \"https://t.co/EblVamM8WW\",\n",
      "            \"utc_offset\": null,\n",
      "            \"verified\": true,\n",
      "            \"withheld_in_countries\": []\n",
      "        }\n",
      "    },\n",
      "    \"source\": \"<a href=\\\"http://twitter.com/download/iphone\\\" rel=\\\"nofollow\\\">Twitter for iPhone</a>\",\n",
      "    \"truncated\": false,\n",
      "    \"user\": {\n",
      "        \"contributors_enabled\": false,\n",
      "        \"created_at\": \"Wed Apr 23 19:56:27 +0000 2008\",\n",
      "        \"default_profile\": false,\n",
      "        \"default_profile_image\": false,\n",
      "        \"description\": \"We are the #UnitedNations\\u2019 health agency - #HealthForAll.\\n\\u25b6\\ufe0f Always check our latest tweets on #COVID19 for updated advice/information.\",\n",
      "        \"entities\": {\n",
      "            \"description\": {\n",
      "                \"urls\": []\n",
      "            },\n",
      "            \"url\": {\n",
      "                \"urls\": [\n",
      "                    {\n",
      "                        \"display_url\": \"who.int\",\n",
      "                        \"expanded_url\": \"http://www.who.int\",\n",
      "                        \"indices\": [\n",
      "                            0,\n",
      "                            23\n",
      "                        ],\n",
      "                        \"url\": \"https://t.co/wVulKuROWG\"\n",
      "                    }\n",
      "                ]\n",
      "            }\n",
      "        },\n",
      "        \"favourites_count\": 11879,\n",
      "        \"follow_request_sent\": false,\n",
      "        \"followers_count\": 9963586,\n",
      "        \"following\": false,\n",
      "        \"friends_count\": 1743,\n",
      "        \"geo_enabled\": true,\n",
      "        \"has_extended_profile\": true,\n",
      "        \"id\": 14499829,\n",
      "        \"id_str\": \"14499829\",\n",
      "        \"is_translation_enabled\": false,\n",
      "        \"is_translator\": false,\n",
      "        \"lang\": null,\n",
      "        \"listed_count\": 34215,\n",
      "        \"location\": \"Geneva, Switzerland\",\n",
      "        \"name\": \"World Health Organization (WHO)\",\n",
      "        \"notifications\": false,\n",
      "        \"profile_background_color\": \"D0ECF8\",\n",
      "        \"profile_background_image_url\": \"http://abs.twimg.com/images/themes/theme1/bg.png\",\n",
      "        \"profile_background_image_url_https\": \"https://abs.twimg.com/images/themes/theme1/bg.png\",\n",
      "        \"profile_background_tile\": true,\n",
      "        \"profile_banner_url\": \"https://pbs.twimg.com/profile_banners/14499829/1610970935\",\n",
      "        \"profile_image_url\": \"http://pbs.twimg.com/profile_images/875476478988886016/_l61qZdR_normal.jpg\",\n",
      "        \"profile_image_url_https\": \"https://pbs.twimg.com/profile_images/875476478988886016/_l61qZdR_normal.jpg\",\n",
      "        \"profile_link_color\": \"0396DB\",\n",
      "        \"profile_sidebar_border_color\": \"8C8C8C\",\n",
      "        \"profile_sidebar_fill_color\": \"D9D9D9\",\n",
      "        \"profile_text_color\": \"000000\",\n",
      "        \"profile_use_background_image\": true,\n",
      "        \"protected\": false,\n",
      "        \"screen_name\": \"WHO\",\n",
      "        \"statuses_count\": 64983,\n",
      "        \"time_zone\": null,\n",
      "        \"translator_type\": \"regular\",\n",
      "        \"url\": \"https://t.co/wVulKuROWG\",\n",
      "        \"utc_offset\": null,\n",
      "        \"verified\": true,\n",
      "        \"withheld_in_countries\": []\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(json.dumps(tweets_json['50'], indent=4, sort_keys=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_punct(line):\n",
    "    \"\"\"\n",
    "    Helper function to remove punctuation EXCEPT for '#''\n",
    "    \n",
    "    Arugment:\n",
    "    line -- string of text\n",
    "    \n",
    "    Returns:\n",
    "    line -- string of text without punctuation\n",
    "    \"\"\"\n",
    "    return line.translate(str.maketrans('', '', string.punctuation.replace('#', '')))\n",
    "\n",
    "def build_terms(line):\n",
    "    \"\"\"\n",
    "    Preprocess the Tweet text by removing stop words, emojis, and punctuation and\n",
    "    stemming, transforming to lowercase and returning the tokens of the text.\n",
    "    \n",
    "    Argument:\n",
    "    line -- string (text) to be preprocessed\n",
    "    \n",
    "    Returns:\n",
    "    line -- a list of tokens corresponding to the input text after the preprocessing\n",
    "    \"\"\"\n",
    "\n",
    "    stemmer = PorterStemmer()\n",
    "    stop_words = set(stopwords.words(\"english\"))\n",
    "    \n",
    "    # transform to lowercase \n",
    "    line =  line.lower() \n",
    "    \n",
    "    # remove non-ASCII terms like emojis and symbols\n",
    "    line = \"\".join(c for c in line if c in string.printable) \n",
    "    \n",
    "    # remove punctuation EXCEPT for hashtags (see remove_punct())\n",
    "    line = remove_punct(line)\n",
    "    \n",
    "    # tokenize the text to get a list of terms\n",
    "    line = line.split() \n",
    "    \n",
    "    # remove html tags, blank spaces like '', and urls\n",
    "    line = [word for word in line if not (re.match(\"^qampa$\" , word) or re.match(\"^amp$\" , word) or re.match(\"^http\" , word)) \n",
    "    and word] \n",
    "    \n",
    "    # remove standalone numbers e.x. '19' but not the 19 from 'covid19'\n",
    "    line = [word for word in line if not word.isnumeric()]\n",
    "    \n",
    "    # add standalone word as token too if it has number e.x. 'covid19' gets tokenized as 'covid19' and 'covid'\n",
    "    line = line + [word.rstrip(string.digits) for word in line if sum([c.isdigit() for c in word]) != 0]\n",
    "    \n",
    "    # remove stopwords\n",
    "    line = [word for word in line if word not in stop_words] \n",
    "    \n",
    "    # perform stemming\n",
    "    line = [stemmer.stem(word) for word in line]\n",
    "    \n",
    "    # add unhashtagged word if it's hashtag is present \n",
    "    # e.x. if #covid is present, we also add covid as a token\n",
    "    line = line + [word.replace('#', '') for word in line if word[0] == '#' ] \n",
    "    \n",
    "    return line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tweet_dict is our output data structure that maps Tweet IDs to their text\n",
    "# note we need to keep the following information\n",
    "# Tweet | Username | Date | Hashtags | Likes | Retweets | Url\n",
    "\n",
    "def create_tweets(tweets_json):\n",
    "    tweet_dict = defaultdict()\n",
    "    tweets = []\n",
    "\n",
    "    for key in tweets_json:\n",
    "        tweet_data = {\n",
    "            'id': tweets_json[key]['id'],\n",
    "            'full_text': tweets_json[key]['full_text'],\n",
    "            'tokens': build_terms(tweets_json[key]['full_text']),\n",
    "            'username': tweets_json[key]['user']['name'],\n",
    "            'date': tweets_json[key]['created_at'],\n",
    "            'hashtags': [key['text'] for key in tweets_json[key]['entities']['hashtags']],\n",
    "            'likes': tweets_json[key]['favorite_count'],\n",
    "            'retweets': tweets_json[key]['retweet_count'], \n",
    "        }\n",
    "\n",
    "        #sometimes the tweet url doesn't exist\n",
    "        try:\n",
    "            tweet_data['url'] = tweets_json[key]['entities']['media'][0]['url']\n",
    "        except:\n",
    "            tweet_data['url'] = None\n",
    "        \n",
    "        tweets.append(tweet_data)\n",
    "    return tweets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create index\n",
    "def create_index(tweets_json):\n",
    "    tweets = create_tweets(tweets_json)\n",
    "    index = defaultdict(list)\n",
    "    title_index = defaultdict()\n",
    "\n",
    "    for tweet in tweets:\n",
    "        title_index[tweet['id']] = tweet\n",
    "        \n",
    "        #current page index keeps track of postision of each word in tweet\n",
    "        #e.x. if our tweet #50 has tokens \"covid health world covid\", our current_page_index looks like:\n",
    "        # {covid -> [50, [0, 3]], health -> [50, [1]], world [50, [2]]}\n",
    "        current_page_index = {}\n",
    "        for position, word in enumerate(tweet['tokens']):\n",
    "            \n",
    "            try:\n",
    "                # if the term is already in the index for the current page (current_page_index)\n",
    "                # append the position to the corresponding list\n",
    "                current_page_index[word][1].append(position)  \n",
    "            except:\n",
    "                # Add the new term as dict key and initialize the array of positions and add the position\n",
    "                current_page_index[word]=[tweet['id'], array('I', [position])] #'I' indicates unsigned int (int in Python)\n",
    "        \n",
    "\n",
    "        for term_page, posting_page in current_page_index.items():\n",
    "            index[term_page].append(posting_page)\n",
    "    \n",
    "    return index, title_index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "defaultdict(<class 'list'>, {'covid': [[50, array('I', [0, 3])], [60, array('I', [0])], [2, array('I', [0])]], 'health': [[50, array('I', [1])], [2, array('I', [1])]], 'world': [[50, array('I', [2])], [60, array('I', [3])]], 'medicine': [[60, array('I', [1])]], 'dog': [[60, array('I', [2])], [2, array('I', [2])]], 'ugh': [[2, array('I', [3])]], 'huh': [[2, array('I', [4])]]})\n",
      "defaultdict(<class 'list'>, {'covid': [0.8165, 0.5, 0.4472], 'health': [0.4082, 0.4472], 'world': [0.4082, 0.5], 'medicine': [0.5], 'dog': [0.5, 0.4472], 'ugh': [0.4472], 'huh': [0.4472]})\n",
      "defaultdict(<class 'int'>, {'covid': 3, 'health': 2, 'world': 2, 'medicine': 1, 'dog': 2, 'ugh': 1, 'huh': 1})\n",
      "defaultdict(<class 'float'>, {'covid': 1.0, 'health': 1.4055, 'world': 1.4055, 'medicine': 2.0986000000000002, 'dog': 1.4055, 'ugh': 2.0986000000000002, 'huh': 2.0986000000000002})\n",
      "defaultdict(None, {50: {'tokens': ['covid', 'health', 'world', 'covid'], 'id': 50}, 60: {'tokens': ['covid', 'medicine', 'dog', 'world'], 'id': 60}, 2: {'tokens': ['covid', 'health', 'dog', 'ugh', 'huh'], 'id': 2}})\n"
     ]
    }
   ],
   "source": [
    "# apply tf-idf\n",
    "# tweets is a list of tokens\n",
    "def create_tfidf_index(tweets):\n",
    "    index = defaultdict(list)\n",
    "    tf = defaultdict(list)  #term frequencies of terms in documents (documents in the same order as in the main index)\n",
    "    df = defaultdict(int)  #document frequencies of terms in the corpus\n",
    "    title_index = defaultdict()\n",
    "    idf = defaultdict(float)\n",
    "\n",
    "\n",
    "    for tweet in tweets:\n",
    "        \n",
    "        title_index[tweet['id']] = tweet\n",
    "        current_page_index = {}\n",
    "\n",
    "        for position, term in enumerate(tweet['tokens']):  ## terms contains page_title + page_text\n",
    "            try:\n",
    "                # if the term is already in the dict append the position to the corresponding list\n",
    "                current_page_index[term][1].append(position)\n",
    "            except:\n",
    "                # Add the new term as dict key and initialize the array of positions and add the position\n",
    "                current_page_index[term]=[tweet['id'], array('I',[position])] #'I' indicates unsigned int (int in Python)\n",
    "\n",
    "        #normalize term frequencies\n",
    "        # Compute the denominator to normalize term frequencies (formula 2 above)\n",
    "        # norm is the same for all terms of a document.\n",
    "        norm = 0\n",
    "        for term, posting in current_page_index.items():\n",
    "            # posting will contain the list of positions for current term in current document. \n",
    "            # posting ==> [current_doc, [list of positions]] \n",
    "            # you can use it to infer the frequency of current term.\n",
    "            \n",
    "            #CHECK THIS!\n",
    "            norm += len(posting[1]) ** 2\n",
    "        norm = math.sqrt(norm)\n",
    "\n",
    "        #calculate the tf(dividing the term frequency by the above computed norm) and df weights\n",
    "        for term, posting in current_page_index.items():\n",
    "            # append the tf for current term (tf = term frequency in current doc/norm)\n",
    "            tf[term].append(np.round(len(posting[1])/norm, 4)) ## SEE formula (1) above\n",
    "            #increment the document frequency of current term (number of documents containing the current term)\n",
    "            df[term] += 1 # increment DF for current term\n",
    "\n",
    "        #merge the current page index with the main index\n",
    "        for term_page, posting_page in current_page_index.items():\n",
    "            index[term_page].append(posting_page)\n",
    "\n",
    "        # Compute IDF following the formula (3) above. HINT: use np.log\n",
    "        for term in df:\n",
    "            idf[term] = 1 + np.round(np.log(float(len(tweets)/df[term])), 4)\n",
    "\n",
    "    return index, tf, df, idf, title_index\n",
    "\n",
    "def test():\n",
    "    tweet1 = {'tokens' : ['covid', 'health', 'world', 'covid'], 'id' : 50}\n",
    "    tweet2 = {'tokens' : ['covid', 'medicine', 'dog', 'world'], 'id' : 60}\n",
    "    tweet3 = {'tokens' : ['covid', 'health', 'dog', 'ugh', 'huh'], 'id' : 2}\n",
    "    tweets = [tweet1, tweet2, tweet3]\n",
    "    index, tf, df, idf, title_index = create_tfidf_index(tweets)\n",
    "    print(index)\n",
    "    print(tf)\n",
    "    print(df)\n",
    "    print(idf)\n",
    "    print(title_index)\n",
    "test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rank_documents(terms, docs, index, idf, tf, title_index):\n",
    "    \"\"\"\n",
    "    Perform the ranking of the results of a search based on the tf-idf weights\n",
    "    \n",
    "    Argument:\n",
    "    terms -- list of query terms\n",
    "    docs -- list of documents, to rank, matching the query\n",
    "    index -- inverted index data structure\n",
    "    idf -- inverted document frequencies\n",
    "    tf -- term frequencies\n",
    "    title_index -- mapping between page id and page title\n",
    "    \n",
    "    Returns:\n",
    "    Print the list of ranked documents\n",
    "    \"\"\"\n",
    "\n",
    "    # I'm interested only on the element of the docVector corresponding to the query terms \n",
    "    # The remaining elements would became 0 when multiplied to the query_vector\n",
    "    # I call doc_vectors[k] for a nonexistent key k, the key-value pair (k,[0]*len(terms)) will be automatically added to the dictionary\n",
    "    doc_vectors = defaultdict(lambda: [0] * len(terms)) \n",
    "    query_vector = [0] * len(terms)\n",
    "\n",
    "    # compute the norm for the query tf\n",
    "    query_terms_count = collections.Counter(terms)  # get the frequency of each term in the query. \n",
    "    # Example: collections.Counter([\"hello\",\"hello\",\"world\"]) --> Counter({'hello': 2, 'world': 1})\n",
    "    #HINT: use when computing tf for query_vector\n",
    "\n",
    "    query_norm = la.norm(list(query_terms_count.values()))\n",
    "\n",
    "    for termIndex, term in enumerate(terms):  #termIndex is the index of the term in the query\n",
    "        if term not in index:\n",
    "            continue\n",
    "\n",
    "        ## Compute tf*idf(normalize TF as done with documents)\n",
    "        query_vector[termIndex] = query_terms_count[term]/query_norm * idf[term] \n",
    "\n",
    "        # Generate doc_vectors for matching docs\n",
    "        for doc_index, (doc, postings) in enumerate(index[term]):\n",
    "            # Example of [doc_index, (doc, postings)]\n",
    "            # 0 (26, array('I', [1, 4, 12, 15, 22, 28, 32, 43, 51, 68, 333, 337]))\n",
    "            # 1 (33, array('I', [26, 33, 57, 71, 87, 104, 109]))\n",
    "            # term is in doc 26 in positions 1,4, .....\n",
    "            # term is in doc 33 in positions 26,33, .....\n",
    "\n",
    "            #tf[term][0] will contain the tf of the term \"term\" in the doc 26            \n",
    "            if doc in docs:\n",
    "                doc_vectors[doc][termIndex] = tf[term][doc_index] * idf[term]  # TODO: check if multiply for idf\n",
    "\n",
    "    # Calculate the score of each doc \n",
    "    # compute the cosine similarity between queyVector and each docVector:\n",
    "    # HINT: you can use the dot product because in case of normalized vectors it corresponds to the cosine similarity\n",
    "    # see np.dot\n",
    "    \n",
    "    doc_scores=[[np.dot(curDocVec, query_vector), doc] for doc, curDocVec in doc_vectors.items() ]\n",
    "    doc_scores.sort(reverse=True)\n",
    "    result_docs = [x[1] for x in doc_scores]\n",
    "    #print document titles instead if document id's\n",
    "    #result_docs=[ title_index[x] for x in result_docs ]\n",
    "    if len(result_docs) == 0:\n",
    "        print(\"No results found, try again\")\n",
    "        query = input()\n",
    "        docs = search_tf_idf(query, index)\n",
    "    #print ('\\n'.join(result_docs), '\\n')\n",
    "    return result_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_tf_idf(query, index):\n",
    "    \"\"\"\n",
    "    output is the list of documents that contain any of the query terms. \n",
    "    So, we will get the list of documents for each query term, and take the union of them.\n",
    "    \"\"\"\n",
    "    query = build_terms(query)\n",
    "    docs = set()\n",
    "    for term in query:\n",
    "        try:\n",
    "            # store in term_docs the ids of the docs that contain \"term\"                        \n",
    "            term_docs=[posting[0] for posting in index[term]]\n",
    "            \n",
    "            # docs = docs Union term_docs\n",
    "            docs = docs.union(set(term_docs))\n",
    "            #docs = set(term_docs)\n",
    "            #print(docs)\n",
    "        except:\n",
    "            #term is not in index\n",
    "            pass\n",
    "        \n",
    "\n",
    "    docs = list(docs)\n",
    "    ranked_docs = rank_documents(query, docs, index, idf, tf, title_index)\n",
    "    return ranked_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time to create the index: 219.74 seconds\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "tweets = create_tweets(tweets_json)\n",
    "start_time = time.time()\n",
    "index, tf, df, idf, title_index = create_tfidf_index(tweets)\n",
    "print(\"Total time to create the index: {} seconds\".format(np.round(time.time() - start_time, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pretty_print_tweet(tweet):\n",
    "    print(\n",
    "    \"\"\"id: {}\n",
    "    username: {}\n",
    "    text: {}\n",
    "    date: {}\n",
    "    hashtags: {}\n",
    "    likes: {}\n",
    "    retweets: {}\n",
    "    url: {}\\n\"\"\".format(tweet['id'], tweet['username'], tweet['full_text'], tweet['date'], tweet['hashtags'], tweet['likes'],\n",
    "                        tweet['retweets'], tweet['url']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Insert your query (i.e.: Computer Science):\n",
      "\n",
      "covid is a risky and dangerous disease\n",
      "\n",
      "======================\n",
      "Top 10 results out of 831 for the searched query:\n",
      "\n",
      "rank: 1\n",
      "id: 1420391266433568777\n",
      "    username: World Health Organization (WHO)\n",
      "    text: #COVID19 is dangerous. The variants are dangerous. \n",
      "Know your risk to lower your risk. Continue to take precautions. \n",
      "\n",
      "Watch this video to find out why üëá https://t.co/KKLh5mj3SI\n",
      "    date: Wed Jul 28 14:30:42 +0000 2021\n",
      "    hashtags: ['COVID19']\n",
      "    likes: 1103\n",
      "    retweets: 704\n",
      "    url: https://t.co/KKLh5mj3SI\n",
      "\n",
      "rank: 2\n",
      "id: 1421115547098488832\n",
      "    username: World Health Organization (WHO)\n",
      "    text: @DrTedros \"Without better testing rates üåç, we cannot fight the disease on the frontline or mitigate the risk of new, more dangerous variants emerging\"-@DrTedros #COVID19 https://t.co/5qRPHqWrzx\n",
      "    date: Fri Jul 30 14:28:44 +0000 2021\n",
      "    hashtags: ['COVID19']\n",
      "    likes: 59\n",
      "    retweets: 28\n",
      "    url: None\n",
      "\n",
      "rank: 3\n",
      "id: 1440667407438123015\n",
      "    username: World Health Organization (WHO)\n",
      "    text: \"Inhaling dirty air increases the risk of:\n",
      "-respiratory diseases like pneumonia, asthma, chronic obstructive pulmonary disease\n",
      "-severe #COVID19.\n",
      "It‚Äôs also a major cause of other noncommunicable diseases like ischaemic heart disease, stroke, and cancers\"-@DrTedros #AirPollution\n",
      "    date: Wed Sep 22 13:20:50 +0000 2021\n",
      "    hashtags: ['COVID19', 'AirPollution']\n",
      "    likes: 262\n",
      "    retweets: 98\n",
      "    url: None\n",
      "\n",
      "rank: 4\n",
      "id: 1438854934020173832\n",
      "    username: World Health Organization (WHO)\n",
      "    text: Non-communicable diseases accounted for 8‚É£0‚É£% of the deaths such as\n",
      "\n",
      "üö® obstructive pulmonary disease\n",
      "üö® stroke\n",
      "üö® ischaemic heart disease\n",
      "\n",
      "More in the üÜï WHO/@ILO Joint Estimates üëâhttps://t.co/mEXoBqYt5g #WorkersHealth #BeatNCDs https://t.co/1eRndOgQN8\n",
      "    date: Fri Sep 17 13:18:43 +0000 2021\n",
      "    hashtags: ['WorkersHealth', 'BeatNCDs']\n",
      "    likes: 126\n",
      "    retweets: 61\n",
      "    url: https://t.co/1eRndOgQN8\n",
      "\n",
      "rank: 5\n",
      "id: 1413498310418178049\n",
      "    username: World Health Organization (WHO)\n",
      "    text: RT @WHO: ‚ÄúThe idea that everyone is protected and it‚Äôs ‚Äúkumbaya‚Äù, and everything goes back to normal - is a very dangerous assumption anywh‚Ä¶\n",
      "    date: Fri Jul 09 14:00:33 +0000 2021\n",
      "    hashtags: []\n",
      "    likes: 0\n",
      "    retweets: 2106\n",
      "    url: None\n",
      "\n",
      "rank: 6\n",
      "id: 1413355648973254664\n",
      "    username: World Health Organization (WHO)\n",
      "    text: RT @WHO: The #COVID19 situation globally is very dangerous with high levels of transmission driven by 4Ô∏è‚É£ major factors:\n",
      "1Ô∏è‚É£ virus variants‚Ä¶\n",
      "    date: Fri Jul 09 04:33:40 +0000 2021\n",
      "    hashtags: ['COVID19']\n",
      "    likes: 0\n",
      "    retweets: 4219\n",
      "    url: None\n",
      "\n",
      "rank: 7\n",
      "id: 1410944860828409861\n",
      "    username: World Health Organization (WHO)\n",
      "    text: \"The [#COVID19] Delta variant is dangerous and is continuing to evolve &amp; mutate, which requires constant evaluation &amp; careful adjustment of the public health response.\"-@DrTedros\n",
      "    date: Fri Jul 02 12:54:03 +0000 2021\n",
      "    hashtags: ['COVID19']\n",
      "    likes: 54\n",
      "    retweets: 38\n",
      "    url: None\n",
      "\n",
      "rank: 8\n",
      "id: 1410944355402137608\n",
      "    username: World Health Organization (WHO)\n",
      "    text: \"Compounded by more transmissible variants, like Delta, which is quickly becoming the dominant strain in many countries, we are in a very dangerous period of this #COVID19 pandemic.\"-@DrTedros\n",
      "    date: Fri Jul 02 12:52:03 +0000 2021\n",
      "    hashtags: ['COVID19']\n",
      "    likes: 42\n",
      "    retweets: 28\n",
      "    url: None\n",
      "\n",
      "rank: 9\n",
      "id: 1445500475579666434\n",
      "    username: World Health Organization (WHO)\n",
      "    text: RT @WHOWPRO: #Meningitis is a dangerous inflammation of the membranes that surround the brain and spinal cord, predominantly caused by infe‚Ä¶\n",
      "    date: Tue Oct 05 21:25:44 +0000 2021\n",
      "    hashtags: ['Meningitis']\n",
      "    likes: 0\n",
      "    retweets: 38\n",
      "    url: None\n",
      "\n",
      "rank: 10\n",
      "id: 1421737159992782849\n",
      "    username: World Health Organization (WHO)\n",
      "    text: RT @WHO: The #COVID19 virus and its variants are dangerous and the Delta variant is the most transmissible variant yet. \n",
      "Dr @mvankerkhove e‚Ä¶\n",
      "    date: Sun Aug 01 07:38:48 +0000 2021\n",
      "    hashtags: ['COVID19']\n",
      "    likes: 0\n",
      "    retweets: 511\n",
      "    url: None\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Insert your query (i.e.: Computer Science):\\n\")\n",
    "query = input()\n",
    "ranked_docs = search_tf_idf(query, index)\n",
    "top = 10\n",
    "\n",
    "print(\"\\n======================\\nTop {} results out of {} for the searched query:\\n\".format(top, len(ranked_docs)))\n",
    "count = 1\n",
    "for d_id in ranked_docs[:top]:\n",
    "    print(\"rank: {}\".format(count))\n",
    "    pretty_print_tweet(title_index[d_id])\n",
    "    count += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('drtedro', 942), ('covid19', 735), ('covid', 735), ('#covid19', 723), ('#covid', 723), ('health', 598), ('rt', 549), ('vaccin', 433), ('countri', 338), ('peopl', 305), ('support', 246), ('pandem', 233), ('global', 229), ('need', 227), ('live', 201), ('#vaccinequ', 195), ('vaccinequ', 195), ('world', 154), ('help', 151), ('care', 151), ('access', 138), ('year', 138), ('work', 125), ('use', 125), ('new', 117), ('today', 116), ('diseas', 115), ('emerg', 114), ('death', 112), ('risk', 111), ('provid', 109), ('servic', 108), ('includ', 108), ('continu', 106), ('call', 105), ('million', 105), ('prevent', 105), ('actacceler', 103), ('protect', 101), ('everi', 98), ('one', 98), ('safe', 96), ('must', 94), ('end', 93), ('also', 93), ('make', 92), ('respons', 91), ('suppli', 91), ('share', 89), ('around', 88), ('develop', 83), ('time', 82), ('medic', 82), ('thank', 81), ('dr', 81), ('commit', 81), ('mani', 80), ('get', 80), ('public', 79), ('variant', 78), ('system', 77), ('take', 76), ('un', 76), ('know', 76), ('case', 76), ('dose', 75), ('month', 75), ('who', 75), ('join', 75), ('increas', 74), ('commun', 71), ('ensur', 71), ('first', 71), ('intern', 70), ('us', 70), ('action', 69), ('treatment', 69), ('olymp', 69), ('patient', 68), ('like', 67), ('women', 67), ('whoafro', 66), ('children', 66), ('whoemro', 65), ('caus', 65), ('effect', 65), ('afghanistan', 64), ('partner', 64), ('high', 64), ('minist', 64), ('sever', 64), ('tokyo', 64), ('report', 63), ('worker', 63), ('tokyo2020', 63), ('learn', 62), ('#mentalhealth', 62), ('mentalhealth', 62), ('#afghanistan', 62), ('togeth', 62), ('qualiti', 61), ('improv', 61), ('popul', 60), ('region', 60), ('reduc', 58), ('essenti', 58), ('target', 58), ('tool', 57), ('technolog', 57), ('day', 56), ('nation', 56), ('recommend', 56), ('reach', 55), ('right', 55), ('life', 55), ('healthi', 55), ('last', 55), ('viru', 55), ('g20org', 55), ('deliv', 53), ('import', 53), ('hospit', 53), ('africa', 52), ('social', 52), ('govern', 52), ('test', 52), ('impact', 51), ('meet', 51), ('even', 51), ('#worldmentalhealthday', 51), ('worldmentalhealthday', 51), ('save', 51), ('#whoacademi', 51), ('whoacademi', 51), ('condit', 50), ('respond', 50), ('let', 50), ('keep', 50), ('food', 50), ('#tokyo', 50), ('challeng', 49), ('#askwho', 49), ('askwho', 49), ('way', 49), ('week', 49), ('state', 49), ('#agoal4al', 49), ('agoal4al', 49), ('#tokyo2020', 49), ('strengthen', 48), ('brief', 48), ('inform', 47), ('least', 47), ('put', 47), ('ask', 46), ('build', 46), ('covax', 46), ('delta', 46), ('sexual', 45), ('infect', 45), ('manag', 45), ('member', 45), ('equit', 44), ('plan', 44), ('level', 44), ('#rc71afro', 44), ('rc71afro', 44), ('achiev', 43), ('critic', 43), ('lead', 43), ('futur', 43), ('may', 43), ('g', 43), ('better', 42), ('manufactur', 42), ('product', 42), ('leader', 41), ('address', 41), ('everyon', 41), ('receiv', 41), ('data', 41), ('almost', 41), ('#healthwork', 40), ('healthwork', 40), ('leadership', 40), ('hub', 40), ('media', 40), ('outbreak', 40), ('#covax', 40), ('would', 40), ('group', 39), ('sinc', 39), ('ill', 39), ('read', 39), ('much', 39), ('find', 39), ('billion', 39), ('coverag', 39), ('prepared', 39), ('next', 39), ('set', 38), ('part', 38), ('team', 38), ('expert', 38), ('control', 38), ('discuss', 38), ('especi', 37), ('human', 37), ('major', 37), ('facil', 37), ('chang', 37), ('mental', 37), ('famili', 37), ('measur', 37), ('inequ', 37), ('face', 37), ('#whoimpact', 37), ('whoimpact', 37), ('epidem', 37), ('#worldbreastfeedingweek', 37), ('worldbreastfeedingweek', 37), ('start', 36), ('affect', 36), ('incl', 36), ('violenc', 36), ('progress', 36), ('still', 36), ('pahowho', 36), ('remain', 36), ('fund', 36), ('avail', 36), ('urgent', 36), ('breastfeed', 36), ('question', 35), ('#healthforal', 35), ('healthforal', 35), ('follow', 35), ('malaria', 35), ('person', 35), ('paralymp', 35), ('die', 34), ('sustain', 34), ('promot', 34), ('explain', 34), ('less', 34), ('fight', 34), ('far', 34), ('septemb', 34), ('#breastfeed', 34), ('#selfcar', 34), ('selfcar', 34), ('effort', 33), ('someon', 33), ('practic', 33), ('unicef', 33), ('other', 33), ('area', 33), ('invest', 32), ('come', 32), ('#airpollut', 32), ('airpollut', 32), ('creat', 32), ('well', 32), ('dont', 32), ('disabl', 32), ('crisi', 32), ('bring', 32), ('ebola', 32), ('capac', 32), ('societi', 32), ('current', 32), ('opportun', 32), ('good', 31), ('number', 31), ('financ', 31), ('open', 31), ('scale', 31), ('mvankerkhov', 31), ('full', 31), ('econom', 31), ('concern', 31), ('vulner', 30), ('age', 30), ('organ', 30), ('research', 30), ('made', 30), ('wellb', 30), ('close', 30), ('suicid', 30), ('key', 30), ('info', 30), ('yet', 30), ('transmiss', 30), ('emmanuelmacron', 30), ('launch', 29), ('resourc', 29), ('seek', 29), ('possibl', 29), ('#malaria', 29), ('deliveri', 29), ('see', 29), ('initi', 29), ('clinic', 28), ('#climatechang', 28), ('climatechang', 28), ('talk', 28), ('physic', 28), ('two', 28), ('prioriti', 28), ('pleas', 28), ('detect', 28), ('young', 28), ('without', 28), ('alreadi', 28), ('situat', 28), ('lifesav', 28), ('studi', 28), ('sid', 28), ('role', 27), ('booster', 27), ('treat', 27), ('step', 27), ('honour', 27), ('stay', 27), ('whowpro', 27), ('babi', 27), ('friend', 27), ('show', 27), ('train', 27), ('identifi', 27), ('#ebola', 27), ('medicin', 27), ('issu', 27), ('spread', 27), ('local', 27), ('immun', 27), ('presid', 27), ('cest', 26), ('could', 26), ('advanc', 26), ('immedi', 26), ('offer', 26), ('univers', 26), ('cancer', 26), ('acceler', 26), ('toward', 26), ('distribut', 26), ('free', 26), ('potenti', 26), ('solidar', 26), ('guidelin', 26), ('g20', 26), ('jensspahn', 26), ('humanitarian', 25), ('fulli', 25), ('sector', 25), ('across', 25), ('air', 25), ('power', 25), ('#suicid', 25), ('mean', 25), ('activ', 25), ('understand', 25), ('heart', 25), ('long', 25), ('visit', 25), ('requir', 25), ('urg', 25), ('#generationequ', 25), ('generationequ', 25), ('hepat', 25), ('foodsystem', 24), ('contribut', 24), ('experi', 24), ('threat', 24), ('go', 24), ('administ', 24), ('collabor', 24), ('prepar', 24), ('origin', 24), ('#lebanon', 24), ('lebanon', 24), ('deploy', 24), ('vital', 23), ('girl', 23), ('kill', 23), ('place', 23), ('abl', 23), ('cours', 23), ('differ', 23), ('seriou', 23), ('best', 23), ('earli', 23), ('remark', 23), ('summit', 23), ('gavi', 23), ('back', 23), ('drmikeryan', 23), ('globalgoalsun', 23), ('platform', 23), ('low', 23), ('act', 23), ('establish', 23), ('africanunion', 23), ('play', 22), ('result', 22), ('whoeurop', 22), ('depress', 22), ('everywher', 22), ('sign', 22), ('leav', 22), ('intellig', 22), ('press', 22), ('mening', 22), ('financi', 22), ('clean', 22), ('strong', 21), ('lack', 21), ('thousand', 21), ('harm', 21), ('among', 21), ('afford', 21), ('respect', 21), ('equal', 21), ('encourag', 21), ('gap', 21), ('miss', 21), ('centr', 21), ('clear', 21), ('adult', 21), ('rate', 21), ('addit', 21), ('engag', 21), ('polit', 21), ('avoid', 21), ('diet', 21), ('#worldhumanitarianday', 21), ('worldhumanitarianday', 21), ('oxygen', 20), ('chikwei', 20), ('healthcar', 20), ('recogn', 20), ('healthier', 20), ('educ', 20), ('decis', 20), ('cant', 20), ('experienc', 20), ('suffer', 20), ('strategi', 20), ('partnership', 20), ('coordin', 20), ('innov', 20), ('look', 20), ('antonioguterr', 20), ('#actogeth', 20), ('actogeth', 20), ('compani', 20), ('lowincom', 20), ('programm', 20), ('noncommunic', 20), ('#unga', 20), ('unga', 20), ('secur', 20), ('workforc', 20), ('countriesdrtedro', 20), ('mother', 20), ('cepivaccin', 20), ('breastfe', 20), ('bahrain', 20), ('#openwho', 19), ('openwho', 19), ('donat', 19), ('twitter', 19), ('limit', 19), ('drive', 19), ('event', 19), ('disrupt', 19), ('benefit', 19), ('special', 19), ('alon', 19), ('common', 19), ('say', 19), ('#letstalk', 19), ('letstalk', 19), ('danger', 19), ('give', 19), ('drug', 19), ('happen', 19), ('child', 19), ('roll', 19), ('approach', 19), ('strateg', 19), ('collect', 19), ('older', 19), ('african', 19), ('produc', 19), ('half', 19), ('mask', 19), ('welcom', 19), ('forward', 19)] \n",
      "\n",
      "[('investafrica1', [0.7559]), ('pill', [0.7071, 0.1961, 0.1857]), ('sexual', [0.6489, 0.189, 0.169, 0.25, 0.2236, 0.2, 0.1796, 0.1961, 0.189, 0.2357, 0.1857, 0.2, 0.3482, 0.2182, 0.2582, 0.1857, 0.2, 0.1961, 0.2673, 0.3162, 0.378, 0.2132, 0.2357, 0.4714, 0.2, 0.3714, 0.3922, 0.4714, 0.8006, 0.2887, 0.378, 0.2085, 0.2294, 0.2236, 0.2, 0.4588, 0.2774, 0.3536, 0.1796, 0.189, 0.189, 0.2425, 0.2041, 0.2, 0.1601]), ('menyusui', [0.6255]), ('uniqu', [0.6, 0.4685, 0.6]), ('der', [0.6, 0.2132, 0.4082]), ('#climatechangehurt', [0.5774]), ('climatechangehurt', [0.5774]), ('whskampala', [0.5774]), ('sept11memori', [0.5547]), ('anim', [0.5345, 0.2425, 0.169, 0.2041]), ('1940sdrtedro', [0.5345]), ('est', [0.5303, 0.2041, 0.1961, 0.2425, 0.1768, 0.189]), ('si', [0.5303]), ('59th', [0.5164, 0.5345]), ('infohttpstco6txzchreyq', [0.5164]), ('whoukrain', [0.5, 0.7071]), ('whoeuroperu', [0.5, 0.7071]), ('support', [0.5, 0.3015, 0.5345, 0.2582, 0.2132, 0.2, 0.2887, 0.2774, 0.2041, 0.1826, 0.2, 0.2425, 0.3333, 0.1741, 0.2041, 0.1925, 0.3922, 0.2132, 0.2041, 0.2041, 0.1961, 0.2132, 0.189, 0.5, 0.2425, 0.2357, 0.2041, 0.1601, 0.2041, 0.1925, 0.189, 0.2085, 0.1826, 0.2673, 0.2357, 0.25, 0.2236, 0.2132, 0.2132, 0.2294, 0.1961, 0.1796, 0.2041, 0.1925, 0.2, 0.2, 0.1961, 0.1291, 0.1857, 0.2887, 0.2041, 0.1857, 0.1961, 0.2673, 0.2182, 0.1796, 0.2, 0.1826, 0.2, 0.2425, 0.189, 0.1715, 0.1961, 0.1961, 0.2673, 0.1796, 0.189, 0.169, 0.1459, 0.2132, 0.3482, 0.1622, 0.2673, 0.2774, 0.2582, 0.189, 0.2582, 0.25, 0.189, 0.3015, 0.1562, 0.1857, 0.1741, 0.2182, 0.2673, 0.2774, 0.2774, 0.3714, 0.2132, 0.189, 0.25, 0.1474, 0.2041, 0.189, 0.189, 0.2085, 0.25, 0.2582, 0.1796, 0.2582, 0.2294, 0.2041, 0.1857, 0.1961, 0.4588, 0.1826, 0.1741, 0.2673, 0.378, 0.2294, 0.1667, 0.3482, 0.2132, 0.1768, 0.1826, 0.1508, 0.3592, 0.2582, 0.2425, 0.1857, 0.1857, 0.1715, 0.1543, 0.2673, 0.1741, 0.2887, 0.2182, 0.1857, 0.2673, 0.2182, 0.189, 0.2085, 0.1925, 0.3592, 0.2236, 0.1857, 0.2774, 0.2673, 0.2582, 0.2774, 0.2774, 0.1826, 0.2041, 0.189, 0.2294, 0.1796, 0.2182, 0.2085, 0.2673, 0.2132, 0.1961, 0.2294, 0.1644, 0.4932, 0.4588, 0.2294, 0.4472, 0.2917, 0.3015, 0.189, 0.4472, 0.189, 0.1715, 0.1622, 0.2085, 0.378, 0.3922, 0.5, 0.4851, 0.2774, 0.3536, 0.1925, 0.2294, 0.25, 0.2182, 0.1857, 0.1741, 0.1826, 0.2236, 0.189, 0.2673, 0.25, 0.2774, 0.2182, 0.2182, 0.2, 0.3381, 0.1768, 0.1581, 0.2, 0.2085, 0.2774, 0.2673, 0.2673, 0.2085, 0.1768, 0.2774, 0.1768, 0.1925, 0.1925, 0.1961, 0.1768, 0.2294, 0.3714, 0.2132, 0.4, 0.2294, 0.1857, 0.2041, 0.1768, 0.1925, 0.2, 0.1796, 0.2357, 0.2294, 0.1961, 0.2357, 0.2182, 0.2041, 0.1826, 0.189, 0.1857, 0.2132, 0.189, 0.2582, 0.2357, 0.2294, 0.2085, 0.2, 0.1925, 0.2182, 0.2, 0.1857, 0.2041, 0.4588, 0.1644, 0.1857, 0.1796, 0.1768, 0.3536, 0.2, 0.2132, 0.2236, 0.2236, 0.2236, 0.2]), ('#letstalk', [0.5, 0.2182, 0.2041, 0.3015, 0.3536, 0.1857, 0.2182, 0.25, 0.4082, 0.2, 0.2236, 0.1715, 0.3333, 0.2, 0.2, 0.2425, 0.2236, 0.2673, 0.1741]), ('letstalk', [0.5, 0.2182, 0.2041, 0.3015, 0.3536, 0.1857, 0.2182, 0.25, 0.4082, 0.2, 0.2236, 0.1715, 0.3333, 0.2, 0.2, 0.2425, 0.2236, 0.2673, 0.1741]), ('hook', [0.5]), ('climat', [0.4867, 0.2294, 0.1796, 0.189, 0.1857, 0.1768, 0.1768, 0.2294, 0.1644, 0.2085, 0.2132, 0.1961, 0.2236, 0.1796]), ('art', [0.4851]), ('maternel', [0.4851]), ('40th', [0.4851]), ('3we', [0.4851]), ('gener', [0.4714, 0.1857, 0.2182, 0.1796, 0.25, 0.2582, 0.2425, 0.1715, 0.189, 0.1925, 0.2132, 0.2673, 0.1796, 0.2774, 0.2132, 0.2085, 0.2041]), ('digit', [0.4714, 0.1622, 0.1796, 0.25, 0.2041, 0.1796, 0.2236, 0.2182, 0.2085, 0.1826, 0.1525, 0.1826, 0.1857, 0.2182]), ('6#foodsystem', [0.4714]), ('paralymp', [0.4588, 0.2357, 0.1826, 0.1857, 0.2294, 0.25, 0.1562, 0.128, 0.1443, 0.1543, 0.1768, 0.1313, 0.1601, 0.1543, 0.1508, 0.1474, 0.1474, 0.1622, 0.1491, 0.1562, 0.1374, 0.1443, 0.1443, 0.1325, 0.1857, 0.1581, 0.1491, 0.1601, 0.1508, 0.1581, 0.1543, 0.1459, 0.1826, 0.2857, 0.1525]), ('carbon', [0.4588, 0.2357]), ('breast', [0.4588, 0.2294, 0.189, 0.189, 0.25, 0.2582, 0.2673, 0.2774, 0.1796, 0.1961]), ('framework', [0.4588, 0.2041, 0.25, 0.1796, 0.1796, 0.1961, 0.1826, 0.1796, 0.1961, 0.2182, 0.2041]), ('selfinterest', [0.4588, 0.1508, 0.603, 0.343]), ('1200pm', [0.4588]), ('whyhttpstcoqrp2lez1jc', [0.4588]), ('7th', [0.4588]), ('composit', [0.4588]), ('ive', [0.4523, 0.2582, 0.1826]), ('g20org', [0.4472, 0.417, 0.5898, 0.3381, 0.4714, 0.5164, 0.4082, 0.4264, 0.378, 0.5164, 0.4714, 0.3536, 0.3536, 0.3381, 0.4851, 0.3714, 0.343, 0.5547, 0.6489, 0.4364, 0.3714, 0.3123, 0.2561, 0.2887, 0.3086, 0.3536, 0.2626, 0.3203, 0.3086, 0.3015, 0.2949, 0.2949, 0.3244, 0.2981, 0.3123, 0.2747, 0.2887, 0.2887, 0.2649, 0.3714, 0.3162, 0.2981, 0.3203, 0.4588, 0.3849, 0.378, 0.3592, 0.3714, 0.3651, 0.3482, 0.3333, 0.3536, 0.4588, 0.4364, 0.417]), ('4th', [0.4472, 0.3651, 0.3162, 0.3849]), ('visit', [0.4472, 0.2673, 0.2673, 0.2357, 0.2673, 0.2236, 0.189, 0.2, 0.2357, 0.2357, 0.2425, 0.2425, 0.2774, 0.2673, 0.1796, 0.2085, 0.1857, 0.2294, 0.2294, 0.2357, 0.2774, 0.1741, 0.2887, 0.2357, 0.25]), ('ecigarett', [0.4472, 0.2582, 0.5164, 0.2774, 0.2085, 0.3922, 0.2132, 0.5, 0.25, 0.2236, 0.417]), ('processdrmikeryan', [0.4472, 0.25]), ('app', [0.4472, 0.2085]), ('algeria', [0.4472]), ('16th', [0.4472]), ('#covid19off', [0.4472]), ('covid19off', [0.4472])] \n",
      "\n",
      "[('multiti', 8.7828), ('marginalis', 8.7828), ('algeria', 8.7828), ('#algeria', 8.7828), ('16th', 8.7828), ('pop', 8.7828), ('si', 8.7828), ('completament', 8.7828), ('vacunado', 8.7828), ('contraer', 8.7828), ('importa', 8.7828), ('todava', 8.7828), ('esperando', 8.7828), ('#inform', 8.7828), ('verifi', 8.7828), ('miser', 8.7828), ('immor', 8.7828), ('arent', 8.7828), ('nine', 8.7828), ('ep', 8.7828), ('#climateactioncal', 8.7828), ('climateactioncal', 8.7828), ('#healthworkersworldwid', 8.7828), ('#climateactionbi', 8.7828), ('healthworkersworldwid', 8.7828), ('climateactionbi', 8.7828), ('worldchang', 8.7828), ('#helacel', 8.7828), ('lacksfamili', 8.7828), ('#healthequ', 8.7828), ('helacel', 8.7828), ('healthequ', 8.7828), ('#climateactionprotect', 8.7828), ('climateactionprotect', 8.7828), ('goodwil', 8.7828), ('momgerm', 8.7828), ('reimagin', 8.7828), ('environmentstransportmobl', 8.7828), ('healthierfairergreen', 8.7828), ('outofschool', 8.7828), ('ictfacilit', 8.7828), ('intim', 8.7828), ('#dayofthegirland', 8.7828), ('dayofthegirland', 8.7828), ('#emrc68', 8.7828), ('#emrc', 8.7828), ('emrc68', 8.7828), ('emrc', 8.7828), ('massoutbreak', 8.7828), ('except', 8.7828)] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# we'll print terms with highest df, tf, and idf\n",
    "print(sorted(df.items(), key=lambda x: x[1], reverse=True)[:500], \"\\n\")\n",
    "print(sorted(tf.items(), key=lambda x: x[1], reverse=True)[:50], \"\\n\")\n",
    "print(sorted(idf.items(), key=lambda x: x[1], reverse=True)[:50], \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# query 0 for example\n",
    "query = 'covid'\n",
    "\n",
    "random.seed(101)\n",
    "\n",
    "# We create a DataFrame with the results of the seacrh (doc_id and pred_rel of the ranked docs)\n",
    "doc_ids, scores = search_tf_idf(query, index)\n",
    "rows = []\n",
    "for i in range(len(scores)):\n",
    "     rows.append([0, doc_ids[i], scores[i], random.randint(0, 1)])\n",
    "    \n",
    "df = pd.DataFrame(rows ,columns=[\"q_id\", \"doc_id\", \"predicted_relevance\", \"y_true\"])\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def precision_at_k(y_true, y_score, k=10):\n",
    "    '''    \n",
    "    Parameters\n",
    "    ----------\n",
    "    y_true: Ground truth (true relevance labels).\n",
    "    y_score: Predicted scores.\n",
    "    k : number of doc to consider.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    precision @k : float\n",
    "    \n",
    "    '''    \n",
    "    order = np.argsort(y_score)[::-1]\n",
    "    y_true = np.take(y_true, order[:k])\n",
    "    relevant = sum(y_true == 1)\n",
    "    return relevant / k "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def avg_precision_at_k(y_true, y_score, k=10):\n",
    "    \n",
    "    '''\n",
    "    Parameters\n",
    "    ----------\n",
    "    y_true: Ground truth (true relevance labels).\n",
    "    y_score: Predicted scores.\n",
    "    k : number of doc to consider.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    average precision @k : float\n",
    "    '''\n",
    "    \n",
    "    gtp = np.sum(y_true == 1) \n",
    "    order = np.argsort(y_score)[::-1]\n",
    "    y_true = np.take(y_true, order[:k])           \n",
    "\n",
    "    ## if all docs are not relevant\n",
    "    if gtp==0:\n",
    "        return 0\n",
    "    n_relevant_at_i = 0\n",
    "    prec_at_i = 0\n",
    "    for i in range(len(y_true)):\n",
    "        if y_true[i] == 1:\n",
    "            n_relevant_at_i += 1 \n",
    "            prec_at_i += n_relevant_at_i / (i + 1) \n",
    "    return prec_at_i / gtp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rr_at_k(y_true, y_score, k=10):\n",
    "    '''\n",
    "    Parameters\n",
    "    ----------\n",
    "    y_true: Ground truth (true relevance labels).\n",
    "    y_score: Predicted scores.\n",
    "    k : number of doc to consider.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    Reciprocal Rank for qurrent query\n",
    "    '''\n",
    "\n",
    "    order = np.argsort(y_score)[::-1] # get the list of indexes of the predicted score sorted in descending order.\n",
    "    y_true = np.take(y_true, order[:k]) # sort the actual relevance label of the documents based on predicted score(hint: np.take) and take first k.\n",
    "    if np.sum(y_true) == 0: # if there are not relevant doument return 0\n",
    "        return 0\n",
    "    return 1 / (np.argmax(y_true == 1) + 1) # hint: to get the position of the first relevant document use \"np.argmax\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dcg_at_k(y_true, y_score,  k=10):\n",
    "    order = np.argsort(y_score)[::-1] # get the list of indexes of the predicted score sorted in descending order.\n",
    "    y_true = np.take(y_true, order[:k]) # sort the actual relevance label of the documents based on predicted score(hint: np.take) and take first k.\n",
    "    gain = (2 ** y_true) - 1 # Compute gain (use formula 7 above)\n",
    "    discounts = np.log2(np.arange(len(y_true)) + 2) # Compute denominator\n",
    "    return np.sum(gain / discounts) #return dcg@k\n",
    "\n",
    "\n",
    "def ndcg_at_k(y_true, y_score, k=10): \n",
    "    order = np.argsort(y_true)[::-1]\n",
    "    ideal = np.take(y_true, order[:k])\n",
    "    dcg_max = dcg_at_k(ideal, ideal, k) # Ideal dcg\n",
    "    if not dcg_max:\n",
    "        return 0\n",
    "    return np.round(dcg_at_k(y_true, y_score, k)/dcg_max, 4)  # return ndcg@k"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
